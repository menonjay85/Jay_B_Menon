<!DOCTYPE html>
<html lang="en"><head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Robotics Engineer | Hi, I’m currently a graduate student in the MS in Robotics program at Northwestern University. You just saw some of my cool projects. I’m passionate about autonomous systems, computer vision, AI, robotic manipulator, and navigation.</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Robotics Engineer" />
<meta name="author" content="Jay" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Hi, I’m currently a graduate student in the MS in Robotics program at Northwestern University. You just saw some of my cool projects. I’m passionate about autonomous systems, computer vision, AI, robotic manipulator, and navigation." />
<meta property="og:description" content="Hi, I’m currently a graduate student in the MS in Robotics program at Northwestern University. You just saw some of my cool projects. I’m passionate about autonomous systems, computer vision, AI, robotic manipulator, and navigation." />
<link rel="canonical" href="http://localhost:4000/projects/Whisker%20Robot/" />
<meta property="og:url" content="http://localhost:4000/projects/Whisker%20Robot/" />
<meta property="og:site_name" content="Robotics Engineer" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Robotics Engineer" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Jay"},"description":"Hi, I’m currently a graduate student in the MS in Robotics program at Northwestern University. You just saw some of my cool projects. I’m passionate about autonomous systems, computer vision, AI, robotic manipulator, and navigation.","headline":"Robotics Engineer","url":"http://localhost:4000/projects/Whisker%20Robot/"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Robotics Engineer" /><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/custom.css">
<noscript><link rel="stylesheet" href="/assets/css/noscript.css" /></noscript>
</head>
<body class="is-preload">

    <div id="wrapper"><header id="header">
  <h1><a href="index.html"><strong>Robotics Engineer</strong></a></h1>
  <nav>
    <ul>
      <li><a href="#footer" class="icon solid fa-info-circle"><b>About Sushma</b></a></li>
    </ul>
  </nav>
</header>
<div id="main">
        <div class="container-fluid">
          <div class="row">
            <div class="col-12 my-5 text-center text-light">
              <h1>Whisker Robot</h1>
              <p>Whisker Robot | April-August 2023.</p>
            </div>
          </div>

          <div class="px-0 px-lg-5">
            <div class="px-0 px-lg-5">
              <div class="px-0 px-lg-5">
                <div class="px-0 px-lg-5">
                  <div class="px-0 px-lg-5">
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/image_neww.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Whisker Robot</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/Frontpage_new.gif" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Whisker Robot Setup in Action <br> The Interior camera view is overlayed onto the top right corner of the Top Camera View. <br> The interior camera view is fed into an ML algorithm to determine the contact location of an object presented to the whiskers.</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                
                <p>
                   <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Motive</h3>
                  
                
                <p>
                   The main goal is to make the robot be able to tell the position (x-coordinate, y-coordinate) <br> of an object that is in contact with the whiskers of the Robot. This is inspired by how rats perceive <br> information about their surrounding environment with the help of their whiskers. <br> <br>

                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Hardware Setup</h3>
                  
                
                <p>
                   <br>
There is a Whisker Robot, and an xy-plotter, both enclosed within an arena. They are actually clamped <br> to the table to avoid any movement of either the Whisker Robot or the xy-plotter setup. There is a  <br> top camera, obtaining the top view of the hardware setup, a front-camera obtaining a front-view of the <br> Whisker Robot and the object that is made to contact the whiskers, then there is an interior camera <br> mounted inside the Whisker Robot which captures images of the membrane which is attatched to the whiskers. <br> This membrane changes with changes in the position of any of the 9 whiskers of the whisker array. <br> <br>

                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/Hardware_Setup_resized_new.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Hardware Setup</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/membrane_resized.jpg" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Interior Camera View</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/topview.jpg" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Top View</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/frontview.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Front View</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Automatic Data Collection</h3>
                  
                
                <p>
                   <br>
I designed an automatic data collection system. An aruco marker is placed on the Whisker Robot which is stationary, <br> and another aruco marker on the part of the xy-plotter that moves along with the object the same magnitude and in  <br> the same direction. Therefore, using these two aruco markers which is read from the top camera, the object position <br> relative to the Whisker Robot is acquired/calculated. The object is moved by a step size of two units (approximately 0.89mm) <br> according to the xy-plotter in the direction that is across (perpendicular) to the whisker array and by a step size of two units <br> according to the xy-plotter (equivalent to approximately 0.66mm) in the direction along (parallel) to the whisker array. <br> It is important to note that the xy-plotter is not a perfect square hence the difference in the step size value across x and y. <br> After completing to traverse the entire breadth of the xy-plotter through mutliple steps, the object is moved a step parallel <br> to the whisker array and this process continues until it reaches the start (0,0) point of the xy plotter which is the closest <br> possible to the Whisker Robot along the direction parallel to the whisker array. <br> <br> <br>

                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/Automatic_Data_Collection.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Sample Dataset (Color coded with serial number which represents increment in Time)</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                
                <p>
                   <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Data Preprocessing</h3>
                  
                
                <p>
                   <ul> <li> Correlate interior camera membrane images with coordinate information of the object based on Serial no. </li> <li> Remove NaN/missing values </li> <li> One hot encoding, specifically Label Encoder for direction (left and right in words to 0 and 1) </li> <li>Remove outliers or suspicious(since contact and non-contact range is decided manually, there is a time when the object(vertical peg) in this case is close to the whisker but not in contact) data during training the model(outlier detection)</li> <li> In the model for classification of contact and non-contact there is some additional pre-processing required.  </li> <li> The classes were unbalanced, i.e. the non-contact datasamples was around 7800 whereas the contact datasamples was around 1600. Since all the non-contact membrane images are exactly the same, there wouldn't be loss of information by reducing the non-contact datasamples, the non-contact datasamples were downsampled and made equal to the number of contact datasamples. </li> <li> Performed stratified split to ensure there is a percentage of each class in the same ratio in both train and test dataset. </li>

</ul> <br>
<br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Machine Learning Algorithm</h3>
                  
                
                <p>
                   <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/Multimodal_Flowchart_resized.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Multimodal Flow Chart</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                
                <p>
                   <br> A neural network is first used to perform a classification task i.e. to classify that the membrane <br> image corresponds to that when there is or isn't contact of the object to any of the whiskers. <br> Another neural network is then incorporated to classify if the membrane image corresponds to that <br> when the object has approached the whisker array from the left direction or from the right direction, <br> only after it has classified that the image is for a object-whisker contact point. <br> <br> Thereafter, it is noteworthy that a separate neural network performs the regression task of predicting <br> the x and y coordinates of the object that came in contact with the whisker array for each the left <br> direction and right direction contact point. This entire structure is depicted through the flow chart above. <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;"><i>Neural Network Structure:</i></h3>
                  
                
                <p>
                   <br>
The colvolution layers extracts features from the input image using filters or weights/matrices <br> which are like a sliding window being multiplied with the input pixels. From the convolution <br> layers we obtain feature maps. The MaxPooling layer results in a downsampling picking up only <br> the important features. In this case I have used a Max-Pooling layer with pool size (2,2),  <br> <br>
The flatten layer is primary responsible for vectorization into a 1D (one-dimension),        <br> for feature aggregation by forming a comprehensive set of features, and to aid in transition <br> into fully connected layers. <br> <br>
Fully Connected layers, also known as Dense layers, is responsible for end to end learning,  <br> used for decision-making and final predictions. It is connected to all th neurons of the previous layer. <br> Here, the model learns more abstract features from the input image. <br> Hyperparameter tuning like experimenting with the learning rate,number of layers, number of filters in each layer, <br> using batch normalization, using regularization, using dropout layers can be done to try to achieve improved results. <br> <br> <i>Below are the detailed diagram of each of the model architectures that constitute the multimodal algorithm:</i> <br>
<br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/classification_contactnoncontact_new.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Classification Model Architecture (Contact/Non-Contact)</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/classification_leftright_new.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Classification Model Architecture (Left Direction/Right Direction)</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/Regression_new.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Regression Model Architecture (x,y coordinates)</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                
                <p>
                   <br> Each of the models was trained and tested on full resolution images (1080,1920,3). A Total of 15,710 data samples is <br> collected via the automatic data collection system. After removing NaN values and suspicious data, there is 9137 data samples <br> remaining. Since x,y coordinate approximate ranges for contact and non-contact is decided manually, it isn't perfectly accurate. <br> Suspicious data is the data sample for those ranges when the object is close to the whisker but not in contact, or just touching <br> the whisker but has not moved the whisker causing any change in the membrane that isn't negligible.After geting rid of this <br> untrustworthy data, a significant improvement in results was observed in the x-coordinate and y-coordinate prediction results in <br> the regression model. <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Results</h3>
                  
                
                <p>
                   <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/graph_1.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Final Result of CNN Multimodal algorithm <br> In an ideal scenario, all the data points would be on the blue dashed line.</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/graph_2.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Final Result of CNN Multimodal algorithm (Individually for left and right direction) <br> In an ideal scenario, all the data points would be on the blue dashed line.</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Accuracy</h3>
                  
                
                <p>
                   <br> Accuracy(%) = (N_total/​N_correct​​)*100 <br> N_correct​ --> number of samples that were correctly classified. <br> N_total​ --> total number of samples in the dataset. <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/contactnoncontact_accuracy.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Training and Test Accuracy across epochs for classification (Contact/Non-Contact) model</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/direction_accuracy.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Training and Test Accuracy across epochs for classification (Left Direction/Right Direction) model</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/regressionleft_accuracy.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Results of regression (x-coordinate, y-coordinate) model for left direction. Predicted VS Ground Truth <br> For an ideal model all of the data points would lie on the dashed red line</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/regressionright_accuracy.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Results of regression (x-coordinate, y-coordinate) model for right direction. Predicted VS Ground Truth <br> For an ideal model all of the data points would lie on the dashed red line</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Loss</h3>
                  
                
                <p>
                   <br>In the classification models I used categorical coss-entropy function to calculate the loss <br> as the in classification there is a class (discrete value) prediction with a confidence level <br> or in other words probability of each of the classes it is trained on. <br>
Whereas, in the regression model the loss function that is used here is mean squared error (MSE). <br> In regression, a continous value prediction is made. <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/categorical_cross_entropy.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light"></figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                
                <p>
                   <br> C = number of classes <br> y_true,i = true value or ground truth <br> y_pred,i= predicted value ​<br> <br> This formula calculates the negative log-likelihood of the true class label under the predicted class probabilities. <br> The goal is to minimize this loss during training. <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/mse.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light"></figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                
                <p>
                   <br> n = number of data points <br> Y_i = true value or ground truth<br> Yhat_i = predicted value <br> <br> MSE achieved on test data after 206 epochs for the regression model trained on only contact data, and only <br> for left direction was = 0.48461 cm^2 <br>
MSE achieved on test data after 206 epochs for the regression model trained on only contact data, and only <br> for right direction was = 0.14036 cm^2 <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/contactnoncontact_loss.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Training and Test Loss across Epochs for classification (Contact/Non-Contact) model</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/direction_loss.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Training and Test Loss across Epochs for classification (Left Direction/Right Direction) model</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/regressionleft_loss.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Training Loss across Epochs for regression left model</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-0 text-center">
                <img class="mx-auto d-block my-3" src="/assets/images/thumbs/regressionright_loss.png" alt="https://www.w3schools.com/bootstrap4/paris.jpg"/>
                <figcaption class="figure-caption text-light">Training Loss across Epochs for regression right model</figcaption>
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Code</h3>
                  
                
                <p>
                  <a href="https://github.com/suzie13/Whisker-Robot-Project/tree/main ">Github Link</a>
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Future Scope</h3>
                  
                
                <p>
                   <br>The future scope of this project is to obtain not just a 2D perspective (x,y coordinates) of the object but the 3D perspective (x,y and z coordinates) of the points of contact of object to the whisker. To further elaborate this, the objective is to obtain a point cloud of all the   contact points (9 contact points) of object to the whisker, thereby better enabling to reconstruct the object that came in contact with the whisker of the Whisker Robot through whisking. <br> <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                <h3 style="font-weight: 600 !important;">Acknowledgements</h3>
                  
                
                <p>
                   <br> Dr. Mitra Hartmann (Principle Investigator at SeNSE LAB) <br> Mr. Kevin James Kleczka (Research Engineer at SeNSE LAB) <br> Professor Matthew Elwin (Co-Director of MS in Robotics program) <br> <br> 
                </p>
                
              </div>
            </div>
            
          
            
            <div class="row">
              <div class="col-12 px-5 text-light content-paragraph">
                
                
                <p>
                  <a href="https://sense-lab.github.io/index.html ">SeNSE LAB  (Sensory and Neural Systems Engineering)</a>
                </p>
                
              </div>
            </div>
            
          
            
            <p>
              
            </p>
            
          
        </div>
      </div>
    </div>
  </div>
  </div>
  </div>
  </div><footer id="footer" class="panel">
  <div class="inner split text-light">
    <div>
      <section>
        <h2>Robotics Engineer</h2>
        <p>Hi, I'm currently a graduate student in the MS in Robotics program at Northwestern University. You just saw some of my cool projects. I'm passionate about autonomous systems, computer vision,  AI, robotic manipulator, and navigation. </p>
      </section><section>
  <h2>Follow me on ...</h2>
  <ul class="icons"><li><a href="https://github.com/menonjay85" class="icon brands fa-github"><span class="label">GitHub</span></a></li></ul>
</section>




<!--<ul class="social-media-list"></ul> -->
<p class="copyright">
        &copy; <a href="mailto:jmenon2@asu.edu">Jay</a>.
      </p>
    </div>
    <div>
      <section>
        <h2>Get in touch</h2>
        <p class="fields">
          <!-- <a href="mailto:jmenon2@asu.edu"></a>. -->
          <a href="mailto:jmenon2@asu.edu">Email</a>
          <br><br>
          <a href="/assets/Sushma_S_Chandra_Resume.pdf">Resume</a>
        </p>
        <p>jmenon2@asu.edu</p>
      </section>
    </div>
  </div>
</footer>
</div>

    <script src="/assets/js/jquery.min.js"></script>
    <script src="/assets/js/jquery.poptrox.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js" integrity="sha384-oBqDVmMz9ATKxIep9tiCxS/Z9fNfEXiDAYTujMAeBAsjFuCZSmKbSSUnQlmh/jp3" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.min.js" integrity="sha384-cuYeSxntonz0PPNlHhBs68uyIAVpIIOZZ5JqeqvYYIcEL727kskC66kF92t6Xl2V" crossorigin="anonymous"></script>
    <script src="/assets/js/browser.min.js"></script>
    <script src="/assets/js/breakpoints.min.js"></script>
    <script src="/assets/js/util.js"></script>
    <script src="/assets/js/main.js"></script>

  </body>

</html>
